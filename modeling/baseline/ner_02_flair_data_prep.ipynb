{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NER dataset is not automatically supported by Flair, so we'll need to format it properly ([more info](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md#reading-your-own-sequence-labeling-dataset))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create text files for train, validation, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: Train 80%, Validation 10%, Test 10%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "ner_dataset = pd.read_csv('/Users/julia/Datasets/ner_corpus/ner_dataset.csv', \n",
    "    encoding='latin1', on_bad_lines='warn', low_memory=False)\n",
    "\n",
    "# The dataset row of every sentence's ending word should be empty, to comply with Flair's format\n",
    "indices_sent_end = ner_dataset[ner_dataset['Sentence #'].notnull()].index - 1\n",
    "ner_dataset.loc[indices_sent_end[1:]] = ['', '', '', '']\n",
    "\n",
    "# Remove the 'Sentence #' column, to comply with Flair's format\n",
    "ner_dataset = ner_dataset.drop(labels='Sentence #', axis=1)\n",
    "\n",
    "# Train-validation-test split (80/10/10)\n",
    "train_df = ner_dataset[:838862]\n",
    "valid_df = ner_dataset[838862:943743]\n",
    "test_df = ner_dataset[943743:]\n",
    "print(f'Splits: Train {len(train_df)/len(ner_dataset)*100:.0f}%, Validation {len(valid_df)/len(ner_dataset)*100:.0f}%, Test {len(test_df)/len(ner_dataset)*100:.0f}%')\n",
    "\n",
    "# Save to text files\n",
    "np.savetxt('/Users/julia/Datasets/ner_corpus/ner_flair_train.txt', train_df.values, fmt='%s')\n",
    "np.savetxt('/Users/julia/Datasets/ner_corpus/ner_flair_valid.txt', valid_df.values, fmt='%s')\n",
    "np.savetxt('/Users/julia/Datasets/ner_corpus/ner_flair_test.txt', test_df.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in text files to Flair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-02 14:06:27,626 Reading data from /Users/julia/Datasets/ner_corpus\n",
      "2022-12-02 14:06:27,627 Train: /Users/julia/Datasets/ner_corpus/ner_flair_train.txt\n",
      "2022-12-02 14:06:27,627 Dev: /Users/julia/Datasets/ner_corpus/ner_flair_valid.txt\n",
      "2022-12-02 14:06:27,628 Test: None\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# Columns in the text files\n",
    "columns = {0: 'text', 1: 'pos', 2: 'ner'}\n",
    "\n",
    "# Data folder in which train, test and dev files reside\n",
    "data_folder = '/Users/julia/Datasets/ner_corpus'\n",
    "\n",
    "# Initialize a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='ner_flair_train.txt',\n",
    "                              dev_file='ner_flair_valid.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the text files were correctly read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34511,\n",
       " 'Sentence: \"Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings .\" → [\"Bush\"/per]',\n",
       " 'Sentence: \"They marched from the Houses of Parliament to a rally in Hyde Park\" → [\"Hyde Park\"/geo]',\n",
       " 'Sentence: \"Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000\"')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.train), corpus.train[0].to_tagged_string('ner'), corpus.train[1].to_tagged_string('ner'), corpus.train[2].to_tagged_string('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4778,\n",
       " 'Sentence: \"They were successful in getting it out of the plane and home\"',\n",
       " 'Sentence: \"When they took it for a float on the river , they were quite surprised by a Coast Guard helicopter coming towards them\" → [\"Coast Guard\"/org]',\n",
       " 'Sentence: \"It turned out that the chopper was homing in on the emergency locator that is automatically activated when the raft is inflated\"')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dev), corpus.dev[0].to_tagged_string('ner'), corpus.dev[1].to_tagged_string('ner'), corpus.dev[2].to_tagged_string('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('glgenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c96b5ccb8e4a9ea98f0b3574a35d5d8e50bd3d4875c501f7cb288f970955458c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
